{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "045bf766",
   "metadata": {},
   "source": [
    "# Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeaf17c4",
   "metadata": {},
   "source": [
    "Web scraping, também conhecido como extração de dados da web, é um método essencial em diversas áreas, como análise de dados, business intelligence, pesquisa de mercado e comércio eletrônico. Essa técnica envolve a coleta e conversão de dados online, incluindo preços de produtos, artigos de notícias, postagens em mídias sociais, informações de contato e dados financeiros, em formatos úteis.\n",
    "\n",
    "Envolve o envio de solicitações HTTP a um site para obter HTML ou outros dados estruturados, posteriormente analisados e usados para recuperar as informações precisas que você precisa das páginas da Web. Esses dados podem estar na forma de links, textos, imagens, etc.\n",
    "\n",
    "Em um mundo cada vez mais orientado por dados, o processo de web scraping combina e organiza informações em escala, permitindo que os tomadores de decisão obtenham conhecimento perspicaz, monitorem tendências e façam escolhas sábias. No entanto, a natureza dinâmica das informações da web, a necessidade de metodologias de raspagem confiáveis e flexíveis e as questões éticas e legais (Dilmegani, 2023) fornecem desafios para a extração de dados da web. Esta investigação inicial estabelecerá as bases para a utilização responsável e bem-sucedida da extração de dados da web.\n",
    "\n",
    "<b>Web Scraping com Python</b>\n",
    "\n",
    "Web scraping pode ser realizado com a ajuda de ferramentas ou bibliotecas Python. Neste artigo, vamos nos concentrar em usar bibliotecas Python para obter nosso conteúdo desejado de um site. Usaremos a biblioteca BeautifulSoup para realizar web scraping porque:\n",
    "\n",
    "Beautiful Soup é uma biblioteca Python projetada para analisar documentos HTML e XML. Ele é utilizado para extrair dados da estrutura HTML de páginas web. O Beautiful Soup pode navegar pelo documento HTML, identificando elementos específicos, como qualquer tag HTML com uma determinada classe ou ID e, em seguida, extraindo as informações desejadas.\n",
    "\n",
    "<b>O Mercado Livre</b>\n",
    "\n",
    "Foi escolhido o ramo do e-commerce para aplicar a técnica de Web scraping e, dentro desse ramo, o site do Mercado Livre foi escolhido por ser líder de market share do e-commerce no Brasil e também por ser muito popular entre os consumidores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd731b0d",
   "metadata": {},
   "source": [
    "## Início"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39519789",
   "metadata": {},
   "source": [
    "### Importando as bibliotecas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22606438",
   "metadata": {},
   "source": [
    "Serão importadas as bibliotecas pandas, requests, datetime e BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2d14b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaca4009",
   "metadata": {},
   "source": [
    "Nosso objetivo é verificar as principais ofertas do dia no site. Então a referência de início será a página principal do Mercado Livre contendo essas informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb003aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.mercadolivre.com.br/ofertas?container_id=MLB779362-1&page=1\"\n",
    "response = requests.get(URL)\n",
    "page = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dce54a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mercadolibre.html','w',encoding = \"utf-8\") as m:\n",
    "    m.write(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60efe497",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(page,'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9eda19",
   "metadata": {},
   "source": [
    "A chave para uma web scraping eficaz é entender a estrutura da página da Web de referência e encontrar a informação de que precisa em suas respectivas tags.\n",
    "\n",
    "Após identificar no site a tag respectiva correspondente ao nome do produto, essa informação é extraída conforme abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "404b471d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo os nomes dos produtos em html\n",
    "def get_items_title(doc):\n",
    "    title_tags = doc.find_all('p', class_='promotion-item__title')\n",
    "    titles = []\n",
    "    for tags in title_tags:\n",
    "        titles.append(tags.text)\n",
    "    return titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0cf013b",
   "metadata": {},
   "source": [
    "O mesmo procedimento é feito para a informação dos preços dos produtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d8ba46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lendo os preços dos produtos em HTML\n",
    "def get_price(doc):\n",
    "    price_tags = doc.find_all('div', class_ = 'andes-money-amount-combo__main-container')\n",
    "    price = []\n",
    "    for tags in price_tags:\n",
    "        price.append(tags.text.replace('Â',''))\n",
    "    return price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7f2e3f",
   "metadata": {},
   "source": [
    "Como estamos fazendo uma requisição de informações em um site, é preciso monitorar a resposta do mesmo para que o processo não tenha falhas. Esse processo de requests é monitorado conforme abaixo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59d61350",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monitorando o status da solicitação\n",
    "def get_doc(URL):\n",
    "    response = requests.get(URL)\n",
    "    doc = BeautifulSoup(response.text, 'html.parser')\n",
    "    if response.status_code != 200:\n",
    "        raise Exception (\"Failed to load page {}\". format(response))\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710794ae",
   "metadata": {},
   "source": [
    "Feito isso, agora é agrupar todas as informações em um dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5fc05dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Agrupando as informações em um dataframe\n",
    "def scrape_multi_pages(i):\n",
    "    URL = 'https://www.mercadolivre.com.br/ofertas?container_id=MLB779362-1&page='\n",
    "    titles,prices = [],[]\n",
    "    \n",
    "    for page in range (1, i+1):\n",
    "        doc = get_doc(URL + str(page))\n",
    "        titles.extend(get_items_title(doc))\n",
    "        prices.extend(get_price(doc))\n",
    "        \n",
    "        itens = {'produto': titles, 'preco': prices}\n",
    "        return pd.DataFrame(itens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4badc74",
   "metadata": {},
   "source": [
    "Atribuindo à variável a quantidade de páginas a serem realizadas as extrações, convertendo a coluna datetime e retirando os caracteres especiais aplicando regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "729596c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertendo a coluna datetime e retirando caracteres especiais\n",
    "df_ml = scrape_multi_pages(20)\n",
    "df_ml['scrapy_datetime'] = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "df_ml['preco'] = df_ml['preco'].str.extract(r'(\\d+[\\.,]?\\d*)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ccca542",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>produto</th>\n",
       "      <th>preco</th>\n",
       "      <th>scrapy_datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Creatina Monohidratada 500g - 100% Pura - Sold...</td>\n",
       "      <td>99,32</td>\n",
       "      <td>2024-03-04 15:08:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Samsung Galaxy A54 5g 256gb 8gb Ram Preto</td>\n",
       "      <td>1.782</td>\n",
       "      <td>2024-03-04 15:08:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Robô Aspirador Wap Robot W90 3 Modos De Limpez...</td>\n",
       "      <td>349</td>\n",
       "      <td>2024-03-04 15:08:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fechadura Digital Fr 10 De Sobrepor Intelbras</td>\n",
       "      <td>269</td>\n",
       "      <td>2024-03-04 15:08:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Impressora Multifuncional 3 Em 1 Ecotank L3250...</td>\n",
       "      <td>1.099</td>\n",
       "      <td>2024-03-04 15:08:10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             produto  preco  \\\n",
       "0  Creatina Monohidratada 500g - 100% Pura - Sold...  99,32   \n",
       "1          Samsung Galaxy A54 5g 256gb 8gb Ram Preto  1.782   \n",
       "2  Robô Aspirador Wap Robot W90 3 Modos De Limpez...    349   \n",
       "3      Fechadura Digital Fr 10 De Sobrepor Intelbras    269   \n",
       "4  Impressora Multifuncional 3 Em 1 Ecotank L3250...  1.099   \n",
       "\n",
       "       scrapy_datetime  \n",
       "0  2024-03-04 15:08:10  \n",
       "1  2024-03-04 15:08:10  \n",
       "2  2024-03-04 15:08:10  \n",
       "3  2024-03-04 15:08:10  \n",
       "4  2024-03-04 15:08:10  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ml.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
